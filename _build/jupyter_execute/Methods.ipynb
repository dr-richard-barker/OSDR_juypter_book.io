{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG3X-tGIpkMA"
   },
   "source": [
    "# AI/ML methods notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMEmAFI5sAuC"
   },
   "source": [
    "# install Python packages\n",
    "This notebook is equipped with a dedicated login shell, tailored to the environment in which it is executed. If you are utilizing your personal compute system, such as a laptop, the login corresponds to your individual compute system login. Conversely, when running this notebook on Google Colab, the login is attributed to the root user. The initiation of Linux shell commands within Jupyter notebook code cells is denoted by a preceding exclamation point (!).\n",
    "\n",
    "In the code cell below, the provided pip commands are employed to install a range of Python libraries essential for the tasks covered in this notebook. It's worth noting that additional Python libraries are automatically installed within our virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPbm2EcyIs_i"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131365,
     "status": "ok",
     "timestamp": 1712869288620,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "bb8-MziuOeFs",
    "outputId": "07e2f2dd-b6a1-4bc7-8643-734d13a88f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.19.5 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy>=1.6.0 (from scikit-learn)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/60.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib>=1.2.0 (from scikit-learn)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/12.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/12.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/12.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/12.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/12.2 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m10.4/12.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/301.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m243.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/38.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/38.2 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/38.2 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/38.2 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/38.2 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/38.2 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/38.2 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/38.2 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/38.2 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m29.4/38.2 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m32.7/38.2 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m36.3/38.2 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.4.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scanpy\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scanpy-1.10.1-py3-none-any.whl.metadata (8.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anndata>=0.8 (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading anndata-0.10.7-py3-none-any.whl.metadata (6.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py>=3.1 (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: joblib in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scanpy) (1.4.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting legacy-api-wrap>=1.4 (from scanpy)\r\n",
      "  Downloading legacy_api_wrap-1.4-py3-none-any.whl.metadata (1.8 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.6 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scanpy) (3.8.4)\r\n",
      "Collecting natsort (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx>=2.7 (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba>=0.56 (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading numba-0.59.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scanpy) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from scanpy) (24.0)\r\n",
      "Requirement already satisfied: pandas>=1.5 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scanpy) (2.2.2)\r\n",
      "Collecting patsy (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynndescent>=0.5 (from scanpy)\r\n",
      "  Downloading pynndescent-0.5.12-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scanpy) (1.4.2)\r\n",
      "Requirement already satisfied: scipy>=1.8 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scanpy) (1.13.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn>=0.13 (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting session-info (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading session_info-1.0.0.tar.gz (24 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting statsmodels>=0.13 (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading statsmodels-0.14.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting umap-learn!=0.5.0,>=0.5 (from scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy)\r\n",
      "  Downloading array_api_compat-1.6-py3-none-any.whl.metadata (1.4 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (4.51.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=8 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from matplotlib>=3.6->scanpy) (2.9.0.post0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.56->scanpy)\r\n",
      "  Downloading llvmlite-0.42.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from pandas>=1.5->scanpy) (2024.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages (from scikit-learn>=0.24->scanpy) (3.4.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from patsy->scanpy) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stdlib_list (from session-info->scanpy)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading stdlib_list-0.10.0-py3-none-any.whl.metadata (3.3 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading scanpy-1.10.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m1.6/2.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading anndata-0.10.7-py3-none-any.whl (122 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/122.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 kB\u001b[0m \u001b[31m254.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/5.4 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\r\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m309.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numba-0.59.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m220.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m323.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading statsmodels-0.14.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/10.7 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/10.7 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/233.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m214.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m194.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading array_api_compat-1.6-py3-none-any.whl (36 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading llvmlite-0.42.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/43.8 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/43.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/43.8 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/43.8 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/43.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/43.8 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/43.8 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/43.8 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.7/43.8 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/43.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m30.7/43.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m34.4/43.8 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m36.8/43.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m39.2/43.8 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m41.6/43.8 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/79.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m150.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: session-info\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for session-info (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8024 sha256=3a4f1eb5849bf586342c7a33d8f5900a41444945e182f51b81f8ddf2ad7a1a3c\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zeypa5q1/wheels/23/da/7c/868424f4a5845ab58cd8686e0eb405e9e1e2d4152bf702c39d\r\n",
      "Successfully built session-info\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: array-api-compat, tqdm, stdlib_list, patsy, networkx, natsort, llvmlite, legacy-api-wrap, h5py, session-info, numba, statsmodels, seaborn, pynndescent, anndata, umap-learn, scanpy\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gseapy\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading gseapy-1.1.2.tar.gz (106 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/106.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn --no-cache\n",
    "!pip install scanpy --no-cache\n",
    "!pip install gseapy --no-cache\n",
    "!pip install pydeseq2 --no-cache\n",
    "!pip install pybiomart==0.1 --no-cache\n",
    "!pip install mygene --no-cache\n",
    "!pip install sklearn_som  --no-cache\n",
    "!pip install pandas --no-cache\n",
    "!pip install numpy --no-cache\n",
    "!pip install matplotlib --no-cache\n",
    "!pip install sklearn-som --no-cache\n",
    "!pip install pyDeseq2 --no-cache\n",
    "!pip install Ensembl_converter --no-cache\n",
    "!pip install mygene --no-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpkDoGrUsMlL"
   },
   "source": [
    "# import Python modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSnhzxTaLN9l"
   },
   "source": [
    "This notebook imports a number of Python modules for use in several notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 14036,
     "status": "ok",
     "timestamp": 1712869302650,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "f079g46t5jTU"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_som.som import SOM\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import scanpy as sc\n",
    "import gseapy as gp\n",
    "from gseapy.plot import gseaplot\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "from gseapy import Msigdb\n",
    "from pybiomart import Server\n",
    "import mygene\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from math import log\n",
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "import operator\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from itertools import islice\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import scipy.stats as stats\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from Ensembl_converter import EnsemblConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxokeQF9rjFG"
   },
   "source": [
    "# define misc helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1712869302653,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "EpOLwn3YqdYA"
   },
   "outputs": [],
   "source": [
    "def set_maxdisplay(n=None):\n",
    "  pd.set_option('display.max_rows', n)\n",
    "  from notebook.services.config import ConfigManager\n",
    "  cm = ConfigManager().update('notebook', {'limit_output': n})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_cXRde853Lu"
   },
   "source": [
    "# Define data ingestion methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCSHct2Opf8X"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1712873653339,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "LwoDZ49r7i_6"
   },
   "outputs": [],
   "source": [
    "def read_meta_data(dataset):\n",
    "  # dataset=255\n",
    "  url = 'https://osdr.nasa.gov/geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=OSD-' + dataset + '_metadata_OSD-' + dataset + '-ISA.zip'\n",
    "  filename = dataset + '-meta.zip'\n",
    "  urlretrieve(url, filename)\n",
    "  !unzip -o {filename} > /dev/null\n",
    "  df = pd.read_csv('s_OSD-' + dataset + '.txt', sep='\\t', header=0)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712873653686,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "eOQxRBfUs6Ir"
   },
   "outputs": [],
   "source": [
    "def read_rnaseq_data(data):\n",
    "  # data = '255_rna_seq_Normalized_Counts'\n",
    "  dataset = data.split('_')[0]\n",
    "  url='https://osdr.nasa.gov/geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=GLDS-' + data + '.csv'\n",
    "  df = pd.read_csv(url)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712873653686,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "yCVR-HkZn08K"
   },
   "outputs": [],
   "source": [
    "def read_phenotype_data(dataset, data):\n",
    "  # dataset = '557'\n",
    "  # data = 'LSDS-1_immunostaining_microscopy_PNAtr_Transformed_Reusable_Results'\n",
    "  url='https://osdr.nasa.gov//geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=' + data + '.csv'\n",
    "  df = pd.read_csv(url)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ga9Pbi5rr1R"
   },
   "source": [
    "# define data filtering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1712869302654,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "vJaculrSRZp_"
   },
   "outputs": [],
   "source": [
    "def filter_cvs(df, thresh=0.5):\n",
    "\n",
    "  # calculate coefficient of variation\n",
    "  cvs=list()\n",
    "  for i in range(len(df)):\n",
    "    m=np.mean(df.iloc[i][1:])\n",
    "    sd=np.std(df.iloc[i][1:])\n",
    "    cvs.append(sd/m)\n",
    "\n",
    "  # plot hist of dist of coev of variation\n",
    "  fig, axs = plt.subplots()\n",
    "  axs.hist(cvs, bins=20)\n",
    "\n",
    "  # keep genes with cv > thresh\n",
    "  indices = list()\n",
    "  for i in range(len(cvs)):\n",
    "    if cvs[i] > thresh:\n",
    "      indices.append(i)\n",
    "  return df.iloc[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1712869302654,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "0kMwy7X10hxR"
   },
   "outputs": [],
   "source": [
    "def drop_nans(df):\n",
    "  # drop NaN rows\n",
    "  df.dropna(inplace=True)\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1712869302654,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "t1tNC979OtBg"
   },
   "outputs": [],
   "source": [
    "def drop_lowcount(df, threshold=10):\n",
    "\n",
    "  # let's drop any low-count genes\n",
    "  print(len(df))\n",
    "  if 'transcript' in df.columns:\n",
    "    df = df[df.drop(columns=['transcript']).sum(axis=1) >= threshold]\n",
    "  elif 'Unnamed: 0' in df.columns:\n",
    "    df = df[df.drop(columns=['Unnamed: 0']).sum(axis=1) >= threshold]\n",
    "    df.rename(columns={\"Unnamed: 0\":\"transcript\"}, inplace=True)\n",
    "  else:\n",
    "    raise Exception(\"check file format\")\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869302654,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "LegH26QSPhp7"
   },
   "outputs": [],
   "source": [
    "def filter_genes(df, drop='non-coding'):\n",
    "  # let's filter protein/ non-protein-coding genes\n",
    "  if drop is None:\n",
    "    return df\n",
    "  server = Server(host='http://www.ensembl.org')\n",
    "  dataset = (server.marts['ENSEMBL_MART_ENSEMBL'].datasets['mmusculus_gene_ensembl'])\n",
    "  gene_info = dataset.query(attributes=['ensembl_gene_id', 'external_gene_name', 'gene_biotype'])\n",
    "  if drop=='non-coding':\n",
    "    filter_genes=gene_info[gene_info['Gene type'] == 'protein_coding']['Gene stable ID']\n",
    "  elif drop=='coding':\n",
    "    filter_genes=gene_info[gene_info['Gene type'] != 'protein_coding']['Gene stable ID']\n",
    "  else:\n",
    "    return df\n",
    "  df=df[df['Unnamed: 0'].isin(filter_genes)]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869302654,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "BIopMUVv2jpH"
   },
   "outputs": [],
   "source": [
    "def filter_data(df, dropnans=False, dropgenes='non-coding', droplowcvs=0):\n",
    "  # drop NANs\n",
    "  if dropnans:\n",
    "    df = drop_nans(df)\n",
    "  # drop non protein-coding genes\n",
    "  if not dropgenes is None:\n",
    "    df = filter_genes(df, drop=dropgenes)\n",
    "  # drop low coef of var genes\n",
    "  if droplowcvs != 0:\n",
    "    df = filter_cvs(df, droplowcvs)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1712869302654,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "7grY5F-aEG_6"
   },
   "outputs": [],
   "source": [
    "def exclude_samples_by_prefix(df, prefix=\"V\", colname=\"Source Name\"):\n",
    "  sample_names=list(df[colname].values)\n",
    "  exclude_names=list()\n",
    "  for sn in sample_names:\n",
    "    if sn.startswith(prefix):\n",
    "      exclude_names.append(sn)\n",
    "  return exclude_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4IuHC13rGZv"
   },
   "source": [
    "# data transformation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869302655,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "JFOBNzQ-rIW4"
   },
   "outputs": [],
   "source": [
    "def transpose_df(df, cur_index_col, new_index_col):\n",
    "  df = df.set_index(cur_index_col).T\n",
    "  df.reset_index(level=0, inplace=True)\n",
    "  cols = [new_index_col] + list(df.columns)[1:]\n",
    "  df.columns = cols\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869302655,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "6jVaYnW9rRTU"
   },
   "outputs": [],
   "source": [
    "def reduce_dims(df, current_key, new_key, n):\n",
    "  #df_t = transpose_df(df, current_key, new_key)\n",
    "  #sdList = df_t.var(axis=1)\n",
    "  sdList = df.std(axis=1)\n",
    "  print('len of sdlist: ', str(len(sdList)))\n",
    "  sdDict = {k: v for v, k in enumerate(sdList)}\n",
    "  if n < 0:\n",
    "    sdDictSorted = sorted(sdDict.items(), key=operator.itemgetter(0), reverse=False)\n",
    "  else:\n",
    "    sdDictSorted = sorted(sdDict.items(), key=operator.itemgetter(0), reverse=True)\n",
    "  topN = sdDictSorted[0:abs(n)]\n",
    "  print('n: ', n)\n",
    "  indices = [x[1] for x in topN]\n",
    "  #df_t = df_t.iloc[indices]\n",
    "  #df_tt= transpose_df(df_t, new_key, current_key)\n",
    "  return df.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1712869302655,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "Kip2oJPk9ArZ"
   },
   "outputs": [],
   "source": [
    "def convert_pd_to_np(df):\n",
    "  X=list()\n",
    "  for col in df.columns[1:]:\n",
    "    X.append(list(df[col]))\n",
    "  return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1712869303044,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "ZqWeNhESyd5z"
   },
   "outputs": [],
   "source": [
    "def get_symbol_from_id(gene_id_list):\n",
    "  # Create an instance of EnsemblConverter\n",
    "  converter = EnsemblConverter()\n",
    "\n",
    "  # Convert Ensembl IDs to gene symbols\n",
    "  result = converter.convert_ids(gene_id_list)\n",
    "\n",
    "  # Print the resulting DataFrame\n",
    "  gene_symbol_list = list()\n",
    "  for i in range(len(result)):\n",
    "    gene_symbol_list.append(result.iloc[i]['Symbol'])\n",
    "\n",
    "  return gene_symbol_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYvmAZ627HKz"
   },
   "source": [
    "# plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1712869303044,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "EozbsWlf7Lf4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plotbox_and_stats(data_, sample_key, field, treatment, space, exclude_samples=[]):\n",
    "  print('field: ', field)\n",
    "  print('excluding samples: ', exclude_samples)\n",
    "  fieldValues = set(data_[field])\n",
    "  value_dict=dict()\n",
    "  results = dict()\n",
    "\n",
    "  flight = str(field) + '_flight'\n",
    "  nonflight= str(field) + '_nonflight'\n",
    "  results[field] = dict()\n",
    "  value_dict[flight] = list()\n",
    "  value_dict[nonflight] = list()\n",
    "  for i in range(len(data_)):\n",
    "    if data_.iloc[i][sample_key] in exclude_samples:\n",
    "      continue\n",
    "    elif treatment is None:\n",
    "      if data_.iloc[i][sample_key].startswith('F'):\n",
    "        value_dict[flight].append(data_.iloc[i][field])\n",
    "      else:\n",
    "        value_dict[nonflight].append(data_.iloc[i][field])\n",
    "    else:\n",
    "      if data_.iloc[i][treatment] == space:\n",
    "        value_dict[flight].append(data_.iloc[i][field])\n",
    "      else:\n",
    "        value_dict[nonflight].append(data_.iloc[i][field])\n",
    "\n",
    "\n",
    "  if len(value_dict[flight]) != 0 and len(value_dict[nonflight]) != 0:\n",
    "    results[field]['t-test p-value'] = float('%.5f' % (stats.ttest_ind(value_dict[flight], value_dict[nonflight], equal_var=False).pvalue))\n",
    "    results[field]['wilcoxon p-value'] = float('%.5f' % (stats.ranksums(value_dict[flight], value_dict[nonflight]).pvalue))\n",
    "    results[field]['ks-test p-value'] = float('%.5f' % (stats.kstest(value_dict[flight], value_dict[nonflight]).pvalue))\n",
    "\n",
    "\n",
    "  print(results)\n",
    "  print('n flight = ', len(value_dict[flight]))\n",
    "  print('n nonflight = ', len(value_dict[nonflight]))\n",
    "  fig,ax = plt.subplots()\n",
    "  ax.boxplot(value_dict.values())\n",
    "  ax.set_xticklabels(value_dict.keys())\n",
    "  #plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "  plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "\n",
    "\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UrOPfUfTfXs"
   },
   "source": [
    "# machine learning methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1712869303044,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "Yt9z5IEuTh4F"
   },
   "outputs": [],
   "source": [
    "# define a method to run the k-means algorithm and then print which cluster each sample belongs to\n",
    "def my_kmeans(df, metadata, k):\n",
    "  # convert df to np\n",
    "  X = convert_pd_to_np(df)\n",
    "  kmeans = KMeans(n_clusters=k, random_state=42, init=\"k-means++\").fit(X)\n",
    "  # and predict each sample\n",
    "  samples = df.columns[1:]\n",
    "  for sample in samples:\n",
    "    print('sample: ', sample, ', cluster: ', kmeans.predict([list(df[sample])]), metadata['255'][metadata['255']['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1712869303044,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "zgUckMDpTl-p"
   },
   "outputs": [],
   "source": [
    "# define a method that graphs the within-cluster-sum-of-squares metric to determine the optimum value of k (the elbow method)\n",
    "def find_k_elbow(df):\n",
    "  # convert df to np\n",
    "  X = convert_pd_to_np(df)\n",
    "  wcss = []\n",
    "  for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42, n_init=i)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "  # plot wcss\n",
    "  x=[i for i in range(1, 11)]\n",
    "  y=wcss\n",
    "\n",
    "  plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869303044,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "NInCRFVjoQdE"
   },
   "outputs": [],
   "source": [
    "def my_gmm(df, metadata, k):\n",
    "  # convert df to np\n",
    "  #df=data['255-normalized']\n",
    "  X = convert_pd_to_np(df)\n",
    "  gm = GaussianMixture(n_components=k, random_state=42).fit(X)\n",
    "  # and predict each sample\n",
    "  samples = df.columns[1:]\n",
    "  # predict probability\n",
    "  for sample in samples:\n",
    "    print('sample: ', sample, ', cluster: ', gm.predict([list(df[sample])]), metadata['255'][metadata['255']['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0])\n",
    "  return gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869303044,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "5FVERHbDoRXW"
   },
   "outputs": [],
   "source": [
    "def find_gmm_elbow(df):\n",
    "  X = convert_pd_to_np(df)\n",
    "  n_components=range(1, 11)\n",
    "  models = [GaussianMixture(n, n_init=42).fit(X) for n in n_components]\n",
    "  aics = [model.aic(X) for model in models]\n",
    "  bics = [model.bic(X) for model in models]\n",
    "  plt.figure(dpi=100)\n",
    "  plt.plot(n_components, aics, label='AIC')\n",
    "  plt.plot(n_components, bics, label='BIC')\n",
    "  plt.legend(loc='best')\n",
    "  plt.xlabel('n_components')\n",
    "  plt.ylabel('AIC or BIC')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VHHZRwjpvgu"
   },
   "source": [
    "# Differential gene expression analysis methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869303044,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "SAIDHbhepzIO"
   },
   "outputs": [],
   "source": [
    "def map_samples_to_conditions(dfT, metadata, metadata_condition_param, condition_0, condition_1):\n",
    "  # map conditions to samples for comparison in DESeq2\n",
    "  condition_dict=dict()\n",
    "  for sample in list(dfT['sample']):\n",
    "    #val=metadata['255'][metadata['255']['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0]\n",
    "    val=metadata[metadata['Sample Name']==sample][metadata_condition_param].values[0]\n",
    "\n",
    "    if val == condition_0:\n",
    "      condition_dict[sample] = 0\n",
    "    else:\n",
    "      condition_dict[sample] = 1\n",
    "\n",
    "\n",
    "  dfT[\"condition\"] = dfT[\"sample\"].map(condition_dict)\n",
    "  conditions=dfT[['sample', 'condition']]\n",
    "\n",
    "  return conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869303045,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "HtFctCTHqdhm"
   },
   "outputs": [],
   "source": [
    "def run_deseq2(df, metadata):\n",
    "  # transpose df\n",
    "  dfT = df.T\n",
    "  dfT.columns=dfT.iloc[0]\n",
    "  dfT=dfT.iloc[1:]\n",
    "  dfT.columns.name=None\n",
    "  dfT = dfT.reset_index().rename(columns={\"index\":\"sample\"})\n",
    "\n",
    "  # map conditions\n",
    "  conditions = map_samples_to_conditions(dfT, metadata, 'Factor Value[Spaceflight]', 'Ground Control', 'Space Flight')\n",
    "\n",
    "  # get count data set up for DESeq2\n",
    "  counts=dfT.drop(columns=['sample', 'condition']).reset_index(drop=True)\n",
    "  counts.applymap(np.isreal)\n",
    "  counts=counts.astype(int)\n",
    "\n",
    "  # run DESeq2\n",
    "  dds=DeseqDataSet(counts=counts, metadata=conditions, design_factors=\"condition\")\n",
    "  dds.deseq2()\n",
    "\n",
    "  return dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1712869303045,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "mtkM88XOqz55"
   },
   "outputs": [],
   "source": [
    "def get_results(dds):\n",
    "  # do DGEA\n",
    "  stats_results=DeseqStats(dds, contrast = ('condition', '0', '1'))\n",
    "\n",
    "  # run summary\n",
    "  stats_results.summary()\n",
    "\n",
    "  # get differentially expressed genes\n",
    "  res = stats_results.results_df\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1712869303045,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "LTT1I17Ardvq"
   },
   "outputs": [],
   "source": [
    "def get_sig_genes(res, pval=0.05, l2fc=0):\n",
    "  sigs = res[(res.padj < pval) & (abs(res.log2FoldChange) > l2fc)]\n",
    "  return sigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1712869303045,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "vtkWQuXmrvuI"
   },
   "outputs": [],
   "source": [
    "def get_dge_ranked_genes(res):\n",
    "  # rank genes from most to least significantly differentially expressed\n",
    "  ranking = res[['stat']].dropna().sort_values('stat', ascending=False)\n",
    "  ranking_index=list(ranking.index)\n",
    "  ranking_index_upper=[x.upper() for x in ranking_index]\n",
    "  ranking.index=ranking_index_upper\n",
    "\n",
    "  return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1712869303045,
     "user": {
      "displayName": "Richard Barker",
      "userId": "08066349230655107502"
     },
     "user_tz": 300
    },
    "id": "OjjASIsmgRx3"
   },
   "outputs": [],
   "source": [
    "def filter_by_dgea(data, metadata,  pval, l2fc):\n",
    "  # run DESeq2\n",
    "  dds = run_deseq2(data, metadata)\n",
    "\n",
    "  # get results\n",
    "  res = get_results(dds)\n",
    "\n",
    "  # get sig genes\n",
    "  sig_genes_df = get_sig_genes(res, pval=pval, l2fc=l2fc)\n",
    "\n",
    "  # get top sig genes\n",
    "  top_genes = list(sig_genes_df.sort_values('padj').index)\n",
    "\n",
    "  # filter data by topn_genes\n",
    "  return data[data['Unnamed: 0'].isin(top_genes)]\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3UrOPfUfTfXs"
   ],
   "provenance": [
    {
     "file_id": "1u8zhD55OOqq6WWVrY0WjiFJDBLDDS_R5",
     "timestamp": 1712869097452
    },
    {
     "file_id": "176UGdwX5vCbL2_lFsLokHF6_wzZCMr5I",
     "timestamp": 1711300868854
    },
    {
     "file_id": "1jb2odfVhZjH6_6hPrXLafCyHaEYkZyJu",
     "timestamp": 1707250131392
    },
    {
     "file_id": "1bUDcgWr6vSQLioLfWtMIA15xpdKYZuUN",
     "timestamp": 1706036000814
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}