{"cells":[{"cell_type":"markdown","metadata":{"id":"PtKbaXzoYN4I"},"source":["# **Mission of the classification notebook**\n","\n","Picture yourself as a data scientist sitting with executives from SpaceX who have received reports that several of their astronauts are complaining of vision impairment.  In order to do a full investigation, their medical team decided to use minimally-invasive [intraocular fine needle aspiration](https://pubmed.ncbi.nlm.nih.gov/8233394/) to take biopsies from the astronauts and their ground-control counterparts.  Using this tissue, they were able to perform immunostaining microscopy as well as RNA sequencing.  They were also able to obtain intraocular pressure measurements from both the astronauts and their ground-control counterparts.  \n","\n","Your goal is to determine if there are [biological pathways](https://en.wikipedia.org/wiki/Biological_pathway) that are responding to conditions in space, because if so, there may be a molecular target that can be used to diagnose, monitor, and/or treat this condition.  But first you must determine if there's any association at all between the RNA-seq gene expression data and the measurements obtained from their medical team.  Your mission is to evaluate the use of random forest and single-layer perceptron classification algorithms to determine if the genes expressed in the retinal tissue are predictive of the phenotypic responses that were observed.  You are also encouraged to try the [logistic regression algorithm](https://en.wikipedia.org/wiki/Logistic_regression) for the same.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"W_cXRde853Lu"},"source":["# Read in the methods\n","\n","Recall that we have put all the custom python methods in a separate notebook which you copied to your Google drive.  We need to read those methods into this notebook so that we can use them here.  You will get prompted to select the gmail address to use to permit access to your google drive for this notebook.\n","\n","Note that we will import the methods in the notebook as \"m\", so all subsequent references to methods in that notebook will be prefixed with \"m.\".\n","\n","**IMPORTANT**: Make sure you put a copy of the methods.ipynb in your google drive by following [these instructions](https://docs.google.com/document/d/1V9a3Z5YKT2Pbef4fgPAwB83bHX-p-rPBRRwo7w5Bi9k/edit?usp=sharing)."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34066,"status":"ok","timestamp":1712958135642,"user":{"displayName":"Richard Barker","userId":"08066349230655107502"},"user_tz":300},"id":"-uEZzf_C66PO","outputId":"7c1b52bc-384a-4f8b-c449-22a29eeb8e65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting import_ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (7.34.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import_ipynb) (5.10.4)\n","Requirement already satisfied: setuptools\u003e=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (67.7.2)\n","Collecting jedi\u003e=0.16 (from IPython-\u003eimport_ipynb)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (0.7.5)\n","Requirement already satisfied: traitlets\u003e=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (0.1.6)\n","Requirement already satisfied: pexpect\u003e4.3 in /usr/local/lib/python3.10/dist-packages (from IPython-\u003eimport_ipynb) (4.9.0)\n","Requirement already satisfied: fastjsonschema\u003e=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003eimport_ipynb) (2.19.1)\n","Requirement already satisfied: jsonschema\u003e=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003eimport_ipynb) (4.19.2)\n","Requirement already satisfied: jupyter-core!=5.0.*,\u003e=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003eimport_ipynb) (5.7.2)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi\u003e=0.16-\u003eIPython-\u003eimport_ipynb) (0.8.4)\n","Requirement already satisfied: attrs\u003e=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003eimport_ipynb) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003eimport_ipynb) (2023.12.1)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003eimport_ipynb) (0.34.0)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003eimport_ipynb) (0.18.0)\n","Requirement already satisfied: platformdirs\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,\u003e=4.12-\u003enbformat-\u003eimport_ipynb) (4.2.0)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect\u003e4.3-\u003eIPython-\u003eimport_ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0-\u003eIPython-\u003eimport_ipynb) (0.2.13)\n","Installing collected packages: jedi, import_ipynb\n","Successfully installed import_ipynb-0.1.4 jedi-0.19.1\n"]}],"source":["# install and import the python module for importing a notebook\n","!pip install import_ipynb\n","import import_ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"9zlbpTykfYa2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive not mounted, so nothing to flush and unmount.\n"]},{"ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-fb51277d1764\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 4\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_and_unmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mnt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--\u003e 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["# mount your google drive to this notebook\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount(\"mnt\", force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"X8F5FyQ47xaq"},"outputs":[],"source":["# import the \"Copy of methods.ipynb\" from your google drive into this notebook\n","m = __import__(\"mnt/MyDrive/Colab Notebooks/Copy of methods\")"]},{"cell_type":"markdown","metadata":{"id":"7V5GOooiPOam"},"source":["# read in the data\n","\n","After reading in the methods, we need to read in the data from the NASA OSDR space biology data repository.  In this notebook, we will  be using the immunostaining microscopy PECAM data from OSD-568, the RNA-seq data from OSD-255, and the tonometry data from OSD-583.\n","\n","After reading in the data from OSDR, we will reduce the dimensions of the RNA-seq data to include only those genes whose [coefficient of variation](https://en.wikipedia.org/wiki/Coefficient_of_variation) is greater than a threshold. This is a form of [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction) that will remove some noise from the gene expression so our classification algorithms can focus on the signal.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ue4aWcjW3Ahv"},"outputs":[],"source":["# define dictionaries for data and metadata\n","data=dict()\n","metadata=dict()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6N8RVfgFN_wf"},"outputs":[],"source":["# read in metadata\n","metadata['255'] = m.read_meta_data('255')\n","metadata['568'] = m.read_meta_data('568')\n","metadata['583'] = m.read_meta_data('583')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8WL7aYMj0v7N"},"outputs":[],"source":["# read in tonometry transformed data from OSD-583\n","data['iop'] = m.read_phenotype_data('583', 'LSDS-16_tonometry_maoTRANSFORMED')\n","print('num samples: ', str(len(list(data['iop']['Sample Name']))))\n","print('samples: ', list(data['iop']['Sample Name']))\n","data['iop'].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUZa7u_YbX_4"},"outputs":[],"source":["# read in the immunostaining PECAM microscopy data from OSD-568\n","data['immunoMICRO-PECAM'] = m.read_phenotype_data('568', 'LSDS-5_immunostaining_microscopy_PECAMtr_TRANSFORMED')\n","print('num records: ', len(data['immunoMICRO-PECAM']))\n","data['immunoMICRO-PECAM'].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZffWrkFvErlN"},"outputs":[],"source":["# use m.read_rnaseq_data() to read in the normalized transcriptomic counts from OSD-255\n","data['255-normalized'] = m.read_rnaseq_data('255_rna_seq_Normalized_Counts')\n","data['255-normalized'].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NU_8K5-3X7_b"},"outputs":[],"source":["# filter genes to those significantly differentially expressed between ground control and space flight\n","rna_seq = m.filter_by_dgea(data['255-normalized'], metadata['255'],  pval=0.05, l2fc=0)\n","print('rna_seq data shape: ', rna_seq.shape)"]},{"cell_type":"markdown","metadata":{"id":"VgHjw8soBPTT"},"source":["**QUESTIONS**\n","\n","1. How many genes in the RNA-seq dataset were there before filtering on the coefficient of variation? After filtering?\n","\n","2. How many samples have IOP measurements? PECAM measurements?\n","\n","3. What is the name of the column in the PECAM data that we will be using as a phenotype measurement?"]},{"cell_type":"markdown","metadata":{"id":"48QixnD8fjG7"},"source":["# Predict intraocular pressure (IOP) from RNA-seq (gene expression) data\n","\n","Not all the samples with IOP measurements had their RNA sequenced.  We will need to first subset the IOP data to match those samples with RNA-seq data."]},{"cell_type":"markdown","metadata":{"id":"hyGbrmKFqEfu"},"source":["## Prepare the data for the algorithms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujGex5bPHqRF"},"outputs":[],"source":["# create a dataframe called iop_subset - a subset of data['iop'] - which uses only \"Retina_Ground\" and \"Retina_Flight\" samples\n","samples=list()\n","for sample in rna_seq.columns[1:]:\n","  samples.append(metadata['255'][metadata['255']['Sample Name']==sample]['Source Name'].values[0])\n","samples_short=list()\n","for sample in samples:\n","  num = \"\"\n","  for c in sample:\n","    if c.isdigit():\n","      num += str(c)\n","  if 'G' in sample:\n","    samples_short.append(\"GC\" + num)\n","  elif 'F' in sample:\n","    samples_short.append(\"F\" + num)\n","iop_subset = data['iop'][data['iop']['Source Name'].isin(samples_short)]\n","iop_subset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpDtYimf29h8"},"outputs":[],"source":["# change the names in the rna_seq dataframe to match those in the iop_subset dataframe\n","rna_seq.columns = ['Unnamed: 0'] + list(iop_subset['Source Name'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLOFSg9der6y"},"outputs":[],"source":["# create numpy array y of IOP values (average of the Avg_Left and Avg_Right) which will be used as the target (response) in our model.\n","y = list()\n","for i in range(len(iop_subset)):\n","  iop_val=(iop_subset.iloc[i]['Avg_Left'] + iop_subset.iloc[i]['Avg_Right'])/2\n","  y.append(iop_val)\n","y = m.np.array(y)\n","y_classes = list()\n","for i in y:\n","  if i \u003e y.mean():\n","    y_classes.append(1)\n","  else:\n","    y_classes.append(0)\n","\n","y = y_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtTnSsn4qF5s"},"outputs":[],"source":["# create numpy array X of rna-seq values\n","X = m.transpose_df(rna_seq, 'Unnamed: 0', 'sample').drop(columns=['sample'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yL06B6Bjxp07"},"outputs":[],"source":["# split up data between training and testing\n","X_train, X_test, y_train, y_test = m.train_test_split(X, y, test_size=0.2, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXppDhyMHwtD"},"outputs":[],"source":["# show the dimensions of the training and testing data\n","print('X train: ', X_train.shape)\n","print('y train: ', len(y_train))\n","print('X test: ', X_test.shape)\n","print('y test: ', len(y_test))"]},{"cell_type":"markdown","metadata":{"id":"I3lyOU5wbbdz"},"source":["**QUESTIONS**\n","\n","1. How many samples are used for training?\n","\n","2. How many samples are used for testing?\n","\n","3. Based on the number of samples used for testing, what are the possible values for the testing accuracy?"]},{"cell_type":"markdown","metadata":{"id":"sXqrSn7r7njv"},"source":["## Build a random forest model to predict IOP from gene expression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cI5mNR4Xqpjf"},"outputs":[],"source":["# run random forest classification on X, y\n","\n","clf = m.RandomForestClassifier(max_depth=8, random_state=23)\n","clf.fit(X_train, y_train)\n","\n","y_train_pred = clf.predict(X_train)\n","train_acc = m.accuracy_score(y_train, y_train_pred)\n","print(\"train accuracy:\", train_acc)\n","\n","y_pred = clf.predict(X_test)\n","test_acc = m.accuracy_score(y_test, y_pred)\n","print(\"test accuracy:\", test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKRvRi4JDdsS"},"outputs":[],"source":["# visualize the random forest\n","num_trees=10\n","for i in range(num_trees):\n","    tree = clf.estimators_[i]\n","    dot_data = m.export_graphviz(tree,\n","                               feature_names=X_train.columns,\n","                               filled=True,\n","                               impurity=False,\n","                               proportion=True)\n","    graph = m.graphviz.Source(dot_data)\n","    display(graph)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7q5JaOUVgZsg"},"outputs":[],"source":["# now create a confusion matrix\n","from sklearn.metrics import confusion_matrix\n","y_pred = clf.predict(X_test)\n","confusion_matrix(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"rhhM9QJvayyZ"},"source":["**QUESTIONS**\n","\n","1. What is the training accuracy of the random forest model? Test accuracy?\n","\n","2. Which genes are used in the 5 decision trees of the random forest model?\n","\n","3. According to the confusion matrix, how many low IOP samples were correctly classified?  correct high IOP?  how many low IOP samples were confused with high IOP samples?"]},{"cell_type":"markdown","metadata":{"id":"6Ytk7E-Rk5Jc"},"source":["## Build a single-layer perceptron model that predicts IOP from gene expression\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfcY_m_Uk-Z7"},"outputs":[],"source":["# run random forest classification on X, y\n","\n","from sklearn.linear_model import Perceptron\n","clf = Perceptron(tol=1e-3, random_state=0)\n","clf.fit(X_train, y_train)\n","\n","y_train_pred = clf.predict(X_train)\n","train_acc = m.accuracy_score(y_train, y_train_pred)\n","print(\"train accuracy:\", train_acc)\n","\n","y_pred = clf.predict(X_test)\n","test_acc = m.accuracy_score(y_test, y_pred)\n","print(\"test accuracy:\", test_acc)\n","\n","print('overall score: ', clf.score(X, y))\n"]},{"cell_type":"markdown","metadata":{"id":"n9PGigL6qP-w"},"source":["**QUESTIONS**\n","\n","1. What is the training accuracy of the SLP model?\n","\n","2. What is the test accuracy of the SLP model?\n","\n","3. What might explain the discrepancy between the training and testing accuracy?"]},{"cell_type":"markdown","metadata":{"id":"GG90bHw2cP_h"},"source":["## BONUS: Build a logistic regression model that predicts IOP from gene expression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHlOMEwi05fH"},"outputs":[],"source":["# now run logistic regression classification on X, y\n","\n","clf = m.LogisticRegression(random_state=23)\n","clf.fit(X_train, y_train)\n","\n","y_train_pred = clf.predict(X_train)\n","train_acc = m.accuracy_score(y_train, y_train_pred)\n","print(\"train accuracy:\", train_acc)\n","\n","y_pred = clf.predict(X_test)\n","test_acc = m.accuracy_score(y_test, y_pred)\n","print(\"test accuracy:\", test_acc)\n"]},{"cell_type":"markdown","metadata":{"id":"XX0dbR0RqvqZ"},"source":["**QUESTIONS**\n","\n","1. What is the training accuracy of the logistic regression model?\n","\n","2. What is the test accuracy of the logistic regression model?\n","\n","3. Which model has a better test accuracy for predicting IOP from gene expression -- the random forest model, the SLP model, or the logistic regression model?"]},{"cell_type":"markdown","metadata":{"id":"qw374GMxbz_G"},"source":["# Predict immunostaining PECAM microscopy from RNA-seq (gene expression)\n","\n","Not all the samples with PECAM measurements had their RNA sequenced.  We will need to first intersect the PECAM data with samples from RNA-seq data."]},{"cell_type":"markdown","metadata":{"id":"s3X9tqs3pNrE"},"source":["## Prepare the data for the algorithms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yL-eJ374d4g"},"outputs":[],"source":["# filter genes to those significantly differentially expressed between ground control and space flight\n","rna_seq = m.filter_by_dgea(data['255-normalized'], metadata['255'],  pval=0.05, l2fc=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgJBGbDpiFAC"},"outputs":[],"source":["# get source names from 255 and sample names in immunoMICRO pecam and intersect the lists and subset the df's\n","samples_255_dict = dict()\n","samples_pecam = list()\n","for i in range(len(metadata['255'])):\n","  sample = metadata['255'].iloc[i]['Source Name']\n","  num = \"\"\n","  for c in sample:\n","    if c.isdigit():\n","      num += str(c)\n","  if \"G\" in sample:\n","    samples_255_dict[\"GC\" + num] = metadata['255'].iloc[i]['Sample Name']\n","\n","  elif \"F\" in sample:\n","    samples_255_dict[\"F\" + num] = metadata['255'].iloc[i]['Sample Name']\n","  else:\n","    continue\n","\n","for sample in data['immunoMICRO-PECAM']['Sample_Name']:\n","  num = \"\"\n","  for c in sample:\n","    if c.isdigit():\n","      num += str(c)\n","  if \"G\" in sample:\n","    samples_pecam.append(\"GC\" + num)\n","  elif \"F\" in sample:\n","    samples_pecam.append(\"F\" + num)\n","  else:\n","    print('neither ground nor space: ',  sample)\n","    continue\n","\n","print('255 samples: ', samples_255_dict.keys())\n","print('pecam samples: ', samples_pecam)\n","# intersect 255 samples with immunoMICRO pecam samples\n","samples_both=list(set(samples_255_dict.keys()) \u0026 set(samples_pecam))\n","print('both: ', samples_both)\n","# subset 255 and pecam samples from intersection\n","gsm_samples = list()\n","for sample in samples_both:\n","  gsm_samples.append(samples_255_dict[sample])\n","print('gsm: ', gsm_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZiyqYyFld2Q"},"outputs":[],"source":["# now subset the rna_seq dataframe with samples from the gsm_samples list\n","X = rna_seq[['Unnamed: 0'] + gsm_samples]\n","print(X.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjzD17uPijuX"},"outputs":[],"source":["# subset the pecam data frame with samples from the both list\n","samples_pecam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pImOqkY5b813"},"outputs":[],"source":["# create numpy array Y of immuno PECAM values\n","y = list()\n","for i in range(len(data['immunoMICRO-PECAM'])):\n","  pecam_val=data['immunoMICRO-PECAM'].iloc[i]['Average']\n","  print('sample: ', data['immunoMICRO-PECAM'].iloc[i]['Sample_Name'])\n","  y.append(pecam_val)\n","\n","y = m.np.array(y)\n","y_classes = list()\n","for p in y:\n","  if p \u003e y.mean():\n","    y_classes.append(1)\n","  else:\n","    y_classes.append(0)\n","\n","y = y_classes\n","print('y = ', y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctM-T5x7-5xu"},"outputs":[],"source":["# create numpy array X of rna-seq values\n","X = m.transpose_df(X, 'Unnamed: 0', 'sample').drop(columns=['sample'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vozP6KVTgrvx"},"outputs":[],"source":["# split up data into training and testing subsets\n","X_train, X_test, y_train, y_test = m.train_test_split(X, y, test_size=0.2, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvQAnaRrC_E_"},"outputs":[],"source":["# show the dimensions of the training and testing data\n","print('X train: ', X_train.shape)\n","print('y train: ', len(y_train))\n","print('X test: ', X_test.shape)\n","print('y test: ', len(y_test))"]},{"cell_type":"markdown","metadata":{"id":"wKEswbbuEXaJ"},"source":["**QUESTIONS**\n","\n","1. How many samples are used for training the model?\n","\n","2. How many samples are used for testing the model?\n","\n","3. Based on the number of samples for testing, what are the possible accuracy scores?"]},{"cell_type":"markdown","metadata":{"id":"r-fopycvh4G7"},"source":["## Build a random forest model to predict PECAM microscopy from gene expression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XiyVtaRqghyf"},"outputs":[],"source":["# now run classification on X, y\n","max_depth=4\n","clf = m.RandomForestClassifier(max_depth=max_depth, random_state=23)\n","clf.fit(X_train, y_train)\n","\n","y_train_pred = clf.predict(X_train)\n","train_acc = m.accuracy_score(y_train, y_train_pred)\n","print(\"train accuracy:\", train_acc)\n","\n","y_pred = clf.predict(X_test)\n","accuracy = m.accuracy_score(y_test, y_pred)\n","print(\"test accuracy:\", accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhtq8RJRg86Z"},"outputs":[],"source":["# visualize forest / feature importance\n","num_trees=10\n","for i in range(num_trees):\n","    tree = clf.estimators_[i]\n","    dot_data = m.export_graphviz(tree,\n","                               feature_names=X_train.columns,\n","                               filled=True,\n","                               impurity=False,\n","                               proportion=True)\n","    graph = m.graphviz.Source(dot_data)\n","    display(graph)"]},{"cell_type":"markdown","metadata":{"id":"lQsoK-vkdPwS"},"source":["**QUESTIONS**\n","\n","1. What is training accuracy of the random forest model?\n","\n","2. What is the test accuracy of the random forest model?\n","\n","3. Which genes are used in the decision trees of the random forest?"]},{"cell_type":"markdown","metadata":{"id":"eLpdB7tZ_AC4"},"source":["## BONUS: Build a logistic regression model to predict PECAM microscopy from gene expression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EuRSufV_I_k"},"outputs":[],"source":["# now run classification on X, y\n","\n","clf = m.LogisticRegression(random_state=23)\n","clf.fit(X_train, y_train)\n","\n","y_train_pred = clf.predict(X_train)\n","train_acc = m.accuracy_score(y_train, y_train_pred)\n","print(\"train accuracy:\", train_acc)\n","\n","y_pred = clf.predict(X_test)\n","accuracy = m.accuracy_score(y_test, y_pred)\n","print(\"test accuracy:\", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"lRCjHafzdhea"},"source":["**QUESTIONS**\n","\n","1. What is the training accuracy of the logistic regression model?\n","\n","2. What is the test accuracy of the logistic regression model?\n","\n","3. Which model has a better test accuracy for predicting PECAM microscopy from gene expression -- the random forest model, the SLP model, or the logistic regression model?"]}],"metadata":{"colab":{"collapsed_sections":["7V5GOooiPOam","48QixnD8fjG7","hyGbrmKFqEfu","sXqrSn7r7njv","6Ytk7E-Rk5Jc","qw374GMxbz_G"],"name":"","provenance":[{"file_id":"18FO8atqLdm5FCq_4hXobPQgogfzxDt_L","timestamp":1712869040423},{"file_id":"18xrRN2RXhYUlD_5LHAYKPmvIqV04BCwK","timestamp":1712444259714},{"file_id":"15TIB8PRAGeK6KzXYTBMuvrtJsggFLIdL","timestamp":1711300923480},{"file_id":"1GHxtB5mfjTpRb9Is9Upcs4D3qPqYNlrr","timestamp":1706556238829},{"file_id":"1jb2odfVhZjH6_6hPrXLafCyHaEYkZyJu","timestamp":1706241588769},{"file_id":"1bUDcgWr6vSQLioLfWtMIA15xpdKYZuUN","timestamp":1706036000814}],"toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}